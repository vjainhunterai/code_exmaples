from datetime import datetime

# Initialize database handler and loggers
db_handler = databaseHandler('mysql+pymysql://admin:Gpoproddb!#!@prod-db.c969yoyq9cyy.us-east-1.rds.amazonaws.com/joblog_metadata')
step_logger = stepLogger(db_handler)
audit_logger = auditLogger(db_handler)

# Example usage
if isinstance(listDir, list):
    for directory in listDir:
        for file in fetchUnprocessedFile:
            file_identifier = file['file_name']  # Adjust this key based on your actual file structure

            if file_identifier not in processed_files:
                start_time = datetime.now()
                try:
                    downloadAndProcessFile(s3Client, bucketName, file, directory, localDirectoryLA)
                    processed_files.add(file_identifier)

                    # File size check after downloading
                    filePath = os.path.join(localDirectoryLA, file_identifier)  # Adjust the path if necessary
                    processor = fileSizeProcessor(filePath)
                    result = processor.processFile()
                    print(result)

                    if result == "File is empty":  # Assuming processFile returns "File is empty" if the file is empty
                        audit_entry = {
                            'exec_id': exec_id,
                            'job_name': 'Process File',
                            'file_name': file_identifier,
                            'file_date': datetime.now(),
                            'total_rec_cnt': 0,
                            'processed_cnt': 0,
                            'job_status': 'Failed',  # Mark status as Failed
                            'rejection_cnt': 0,
                            'rejection_rsn': 'File is empty',
                            's3_last_modified_date': datetime.now()
                        }
                        end_time = datetime.now()
                        step_logger.logStep(
                            execId='aaaaa',  # Example exec_id, replace with your actual value
                            jobName="Process File",
                            fileName=file_identifier,
                            startTime=start_time,
                            endTime=end_time,
                            srcCnt=0,
                            tgtCnt=0,
                            lkpCnt=0,
                            rejCnt=0,
                            jobStatus="Failed"
                        )
                    else:
                        # Count the number of records in the file
                        with open(filePath, 'r') as f:
                            src_cnt = sum(1 for line in f) - 1  # Subtract 1 to ignore the header row

                        audit_entry = {
                            'exec_id': exec_id,
                            'job_name': 'Process File',
                            'file_name': file_identifier,
                            'file_date': datetime.now(),
                            'total_rec_cnt': src_cnt,
                            'processed_cnt': 0,
                            'job_status': 'WIP',  # Mark status as WIP
                            'rejection_cnt': 0,
                            'rejection_rsn': '',
                            's3_last_modified_date': datetime.now()
                        }
                        end_time = datetime.now()
                        step_logger.logStep(
                            execId='aaaaa',  # Example exec_id, replace with your actual value
                            jobName="Process File",
                            fileName=file_identifier,
                            startTime=start_time,
                            endTime=end_time,
                            srcCnt=src_cnt,
                            tgtCnt=0,
                            lkpCnt=0,
                            rejCnt=0,
                            jobStatus="Success"
                        )

                    # Log the audit entry
                    audit_logger.logAudit(audit_entry)

                except Exception as e:
                    # Log the failure in the audit entry
                    audit_entry = {
                        'exec_id': exec_id,
                        'job_name': 'Process File',
                        'file_name': file_identifier,
                        'file_date': datetime.now(),
                        'total_rec_cnt': 0,
                        'processed_cnt': 0,
                        'job_status': 'Failed',  # Mark status as Failed due to error
                        'rejection_cnt': 0,
                        'rejection_rsn': f'Error: {e}',
                        's3_last_modified_date': datetime.now()
                    }
                    end_time = datetime.now()
                    step_logger.logStep(
                        execId='aaaaa',  # Example exec_id, replace with your actual value
                        jobName="Process File",
                        fileName=file_identifier,
                        startTime=start_time,
                        endTime=end_time,
                        srcCnt=0,
                        tgtCnt=0,
                        lkpCnt=0,
                        rejCnt=0,
                        jobStatus="Failed"
                    )
                    audit_logger.logAudit(audit_entry)

# Close database connection
db_handler.close()
print("Database connection closed.")
