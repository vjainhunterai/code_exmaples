import os
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from datetime import datetime
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import hmac

class DataLoader:
    def __init__(self, file_type, table_name, directory_path, delimiter, db_uri, load_user):
        self.file_type = file_type.lower()
        self.table_name = table_name
        self.directory_path = directory_path
        self.delimiter = delimiter
        self.db_uri = db_uri
        self.load_user = load_user
        self.engine = create_engine(db_uri)
        self.Session = sessionmaker(bind=self.engine)
    
    def load_data(self):
        files = [f for f in os.listdir(self.directory_path) if self.file_type in f.lower()]
        for file in files:
            file_path = os.path.join(self.directory_path, file)
            data = self._read_file(file_path)
            if data is not None:
                data = self._add_hash_key(data)
                data = self._add_metadata(data)
                self._insert_data(data)
    
    def _read_file(self, file_path):
        try:
            return pd.read_csv(file_path, delimiter=self.delimiter)
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
            return None

    def _add_hash_key(self, data):
        def hash_row(row):
            concatenated = ''.join(str(row[col]) for col in data.columns)
            digest = hmac.HMAC(b'secret_key', hashes.SHA256(), backend=default_backend())
            digest.update(concatenated.encode('utf-8'))
            return digest.finalize().hex()
        
        data.insert(0, 'hash_key', data.apply(hash_row, axis=1))
        return data
    
    def _add_metadata(self, data):
        data['load_user'] = self.load_user
        data['load_date'] = datetime.now()
        return data

    def _insert_data(self, data):
        try:
            with self.engine.begin() as connection:
                data.to_sql(self.table_name, con=connection, if_exists='append', index=False)
        except Exception as e:
            print(f"Error inserting data into {self.table_name}: {e}")
    
    def close(self):
        self.engine.dispose()

 # Example usage
    db_uri = "mysql+pymysql://admin:Gpoproddb!#!@prod-db.c969yoyq9cyy.us-east-1.rds.amazonaws.com/joblog_metadata"
    file_type = 'AP'
    table_name = 'target_table'
    directory_path = 'C:\\Users\\jvineet\\PycharmProjects\\PythonLearnings\\Data\\processed\\processed_valid\\AP'
    delimiter = '|'
    db_uri = db_uri
    load_user = 'admin'
    loader = dataLoader(file_type=file_type, table_name=table_name, directory_path=directory_path, delimiter=delimiter,
                        db_uri=db_uri, load_user='admin')
    loader.load_data()
    loader.close()
    end_time = datetime.now()
    db_handler = databaseHandler('mysql+pymysql://admin:Gpoproddb!#!@prod-db.c969yoyq9cyy.us-east-1.rds.amazonaws.com/joblog_metadata')
    audit_logger = auditLogger(db_handler)
    # Update an existing audit entry
    updated_values = {
        'job_status': 'Completed',
        'processed_cnt': 100,
        'rejection_rsn': invalid_rows_count  # Clear rejection reason if processing was successful
    }
    audit_logger.updateAudit(exec_id, updated_values)



